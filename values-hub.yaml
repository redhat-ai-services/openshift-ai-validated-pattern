clusterGroup:
  name: hub
  isHubCluster: true
  namespaces:
    - open-cluster-management
    - vault
    - golang-external-secrets
    # - redhat-ods-operator:
    #    operatorGroup: true
    #    targetNamespaces:
    - openshift-pipelines
    - openshift-serverless:
        operatorGroup: true
        targetNamespaces: []
    - openshift-nfd:
        operatorGroup: true
    - nvidia-gpu-operator:
        operatorGroup: true
    - ai-example-training:
        labels:
          opendatahub.io/dashboard: "true"
    - ai-example-single-model-serving:
        labels:
          opendatahub.io/dashboard: "true"
    - ai-example-multi-model-serving:
        labels:
          opendatahub.io/dashboard: "true"
          modelmesh-enabled: "true"

  subscriptions:
    # acm:
    #   name: advanced-cluster-management
    #   namespace: open-cluster-management
    #   channel: release-2.10
      #csv: advanced-cluster-management.v2.6.1
    nvidia-gpu:
      name: gpu-operator-certified
      namespace: nvidia-gpu-operator
      source: certified-operators
      channel: stable
    pipelines:
      name: openshift-pipelines-operator-rh
      namespace: openshift-operators
      channel: latest
    serverless:
      name: serverless-operator
      namespace: openshift-serverless
      channel: stable
    servicemesh:
      name: servicemeshoperator
      namespace: openshift-operators
      channel: stable
    # Don't install RHOAI via validated patterns
    # RHOAI must be installed after service mesh and other dependencies are installed or it will break. 
    # The RHOAI Application will install the operator after a validation check has passed
    # rhoai:
    #   name: rhods-operator
    #   namespace: redhat-ods-operator
    #   channel: fast
    nfd:
      name: nfd
      namespace: openshift-nfd
      channel: stable
  projects:
    - hub
    - openshift-ai
    - ai-example-workload
    - gpu
    - pipelines
    - examples
  # Explicitly mention the cluster-state based overrides we plan to use for this pattern.
  # We can use self-referential variables because the chart calls the tpl function with these variables defined
  sharedValueFiles:
    - '/overrides/values-{{ $.Values.global.clusterPlatform }}.yaml'
  # sharedValueFiles is a flexible mechanism that will add the listed valuefiles to every app defined in the
  # applications section. We intend this to supplement and possibly even replace previous "magic" mechanisms, though
  # we do not at present have a target date for removal.
  #
  # To replicate the "classic" magic include structure, the clusterGroup would need all of these
  # sharedValueFiles, in this order:
  #   - '/overrides/values-{{ $.Values.global.clusterPlatform }}.yaml'
  #   - '/overrides/values-{{ $.Values.global.clusterPlatform }}-{{ $.Values.global.clusterVersion }}.yaml'
  #   - '/overrides/values-{{ $.Values.global.clusterPlatform }}-{{ $.Values.clusterGroup.name }}.yaml'
  #   - '/overrides/values-{{ $.Values.global.clusterVersion }}-{{ $.Values.clusterGroup.name }}.yaml"
  #   - '/overrides/values-{{ $.Values.global.localClusterName }}.yaml'

  # This kind of variable substitution will work with any of the variables the Validated Patterns operator knows
  # about and sets, so this is also possible, for example:
  #   - '/overrides/values-{{ $.Values.global.hubClusterDomain }}.yaml'
  #   - '/overrides/values-{{ $.Values.global.localClusterDomain }}.yaml'
  applications:
    # acm:
    #   name: acm
    #   namespace: open-cluster-management
    #   project: hub
    #   path: common/acm
    #   ignoreDifferences:
    #     - group: internal.open-cluster-management.io
    #       kind: ManagedClusterInfo
    #       jsonPointers:
    #         - /spec/loggingCA
    vault:
      name: vault
      namespace: vault
      project: hub
      path: common/hashicorp-vault
    golang-external-secrets:
      name: golang-external-secrets
      namespace: golang-external-secrets
      project: hub
      path: common/golang-external-secrets
    openshift-ai:
      name: openshift-ai
      project: openshift-ai
      path: kustomization/openshift-ai/aggregate/overlays/fast
      kustomize: true
    nfd:
      name: nfd
      project: gpu
      path: kustomization/nfd/instance/overlays/default
      kustomize: true
    ai-example-datascience-pipelines:
      name: ai-example-datascience-pipelines
      project: ai-example-workload
      path: kustomization/ai-example/datascience-pipelines/overlays/rhoai-fast
      kustomize: true
    ai-example-dsp-example-pipeline:
      name: ai-example-dsp-example-pipeline
      project: ai-example-workload
      path: kustomization/ai-example/dsp-example-pipeline/overlays/rhoai-fast
      kustomize: true
    ai-example-multi-model-serving:
      name: ai-example-multi-model-serving
      project: ai-example-workload
      path: kustomization/ai-example/multi-model-serving/overlays/rhoai-fast
      kustomize: true
    ai-example-multi-model-serving-minio:
      name: ai-example-multi-model-serving-minio
      project: ai-example-workload
      path: kustomization/ai-example/multi-model-serving-minio/overlays/rhoai-fast
      kustomize: true
    ai-example-single-model-serving-tgis:
      name: ai-example-single-model-serving-tgis
      project: ai-example-workload
      path: kustomization/ai-example/single-model-serving-tgis/overlays/rhoai-fast
      kustomize: true
    ai-example-single-model-serving-minio:
      name: ai-example-single-model-serving-minio
      project: ai-example-workload
      path: kustomization/ai-example/single-model-serving-minio/overlays/rhoai-fast
      kustomize: true
    ai-example-workbenches:
      name: ai-example-workbenches
      project: ai-example-workload
      path: kustomization/ai-example/workbenches/overlays/rhoai-fast
      kustomize: true
      ignoreDifferences:
        - kind: Notebook
          group: kubeflow.org
          jqPathExpressions:
            - .spec.template.spec.containers[] | select(.name == "oauth-proxy")
            - .spec.template.spec.volumes[] | select(.name == "oauth-config")
            - .spec.template.spec.volumes[] | select(.name == "tls-certificates")

    # openshift-pipelines:
    #   name: openshift-pipelines
    #   namespace: openshift-pipelines
    #   project: pipelines
    #   path: charts/all/pipelines
  imperative:
    # NOTE: We *must* use lists and not hashes. As hashes lose ordering once parsed by helm
    # The default schedule is every 10 minutes: imperative.schedule
    # Total timeout of all jobs is 1h: imperative.activeDeadlineSeconds
    # imagePullPolicy is set to always: imperative.imagePullPolicy
    # For additional overrides that apply to the jobs, please refer to
    # https://hybrid-cloud-patterns.io/imperative-actions/#additional-job-customizations
    jobs:
      - name: hello-world
        # ansible playbook to be run
        playbook: common/ansible/playbooks/hello-world/hello-world.yaml
        # per playbook timeout in seconds
        timeout: 234
        # verbosity: "-v"
  managedClusterGroups:
    exampleRegion:
      name: group-one
      acmlabels:
        - name: clusterGroup
          value: group-one
      helmOverrides:
        - name: clusterGroup.isHubCluster
          value: false
          # Before enabling cluster provisioning, ensure AWS and/or Azure
          #   credentials and OCP pull secrets are defined in Vault.
          #   See values-secret.yaml.template
          #
          #clusterPools:
          #  exampleAWSPool:
          #    name: aws-ap
          #    openshiftVersion: 4.10.18
          #    baseDomain: blueprints.rhecoeng.com
          #    platform:
          #      aws:
          #        region: ap-southeast-2
          #    clusters:
          #    - One
          #
          #  exampleAzurePool:
          #    name: azure-us
          #    openshiftVersion: 4.10.18
          #    baseDomain: blueprints.rhecoeng.com
          #    platform:
          #      azure:
          #        baseDomainResourceGroupName: dojo-dns-zones
          #        region: eastus
          #    clusters:
          #    - Two
          #    - Three
#  To have apps in multiple flavors, use namespaces and use helm overrides as appropriate
#
#    pipelines:
#      name: pipelines
#      namespace: production
#      project: datacenter
#      path: applications/pipeline
#      repoURL: https://github.com/you/applications.git
#      targetRevision: stable
#      overrides:
#      - name: myparam
#        value: myparam
#
#    pipelines_staging:
#    - name: pipelines
#      namespace: staging
#      project: datacenter
#      path: applications/pipeline
#      repoURL: https://github.com/you/applications.git
#      targetRevision: main
#
#   Additional applications
#   Be sure to include additional resources your apps will require
#   +X machines
#   +Y RAM
#   +Z CPU
#    vendor-app:
#      name: vendor-app
#      namespace: default
#      project: vendor
#      path: path/to/myapp
#      repoURL: https://github.com/vendor/applications.git
#      targetRevision: main

#  managedSites:
#    factory:
#      name: factory
#      # repoURL: https://github.com/dagger-refuse-cool/manuela-factory.git
#      targetRevision: main
#      path: applications/factory
#      helmOverrides:
#      - name: site.isHubCluster
#        value: false
#      clusterSelector:
#        matchExpressions:
#        - key: vendor
#          operator: In
#          values:
#            - OpenShift
